{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Document Summarizer\n",
    "This notebook demonstrates extractive and abstractive summarization on business documents while preserving diverse viewpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install dependencies from requirements.txt and import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "files = sorted(glob.glob('sample_data/*.txt'))\n",
    "docs = {Path(f).stem: open(f).read() for f in files}\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive Summarization\n",
    "We use the Sumy LexRank algorithm with basic viewpoint preservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "\n",
    "def extractive_summary(text, sentences=2, preserve_viewpoints=True):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer('english'))\n",
    "    summarizer = LexRankSummarizer()\n",
    "    summary = summarizer(parser.document, sentences)\n",
    "    sent_text = [str(s) for s in summary]\n",
    "    if preserve_viewpoints:\n",
    "        viewpoint_sents = [s for s in text.split('\n') if any(k in s.lower() for k in ['however', 'but', 'concern', 'question'])]\n",
    "        if viewpoint_sents and not any(v in sent_text for v in viewpoint_sents):\n",
    "            sent_text.append(viewpoint_sents[0])\n",
    "    return ' '.join(sent_text)\n",
    "\n",
    "for name, text in docs.items():\n",
    "    print(name, ':', extractive_summary(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive Summarization\n",
    "Using a Transformer model with length control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model_name = 'sshleifer/distilbart-cnn-12-6'\n",
    "summarizer = pipeline('summarization', model=model_name)\n",
    "\n",
    "def abstractive_summary(text, max_length=60, min_length=20):\n",
    "    summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text']\n",
    "    return summary\n",
    "\n",
    "for name, text in docs.items():\n",
    "    print(name, ':', abstractive_summary(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "We calculate ROUGE and a simple viewpoint coverage metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def viewpoint_coverage(original, summary):\n",
    "    viewpoints = [s for s in original.split('\n') if any(k in s.lower() for k in ['however', 'but', 'concern', 'question'])]\n",
    "    if not viewpoints:\n",
    "        return 1.0\n",
    "    covered = sum(1 for v in viewpoints if v.strip() in summary)\n",
    "    return covered / len(viewpoints)\n",
    "\n",
    "def evaluate(original, summary):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(original, summary)\n",
    "    coverage = viewpoint_coverage(original, summary)\n",
    "    return {**scores, 'viewpoint_coverage': coverage}\n",
    "\n",
    "for name, text in docs.items():\n",
    "    summ = abstractive_summary(text)\n",
    "    print(name, evaluate(text, summ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length-Controlled Summaries for Different Audiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiences = {'executive': 30, 'detailed': 60}\n",
    "for audience, length in audiences.items():\n",
    "    print(f'\\nAudience: {audience}')\n",
    "    for name, text in docs.items():\n",
    "        print(name, ':', abstractive_summary(text, max_length=length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook demonstrated extractive and abstractive summarization with viewpoint preservation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
